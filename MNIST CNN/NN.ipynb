{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import imgaug.augmenters as iaa\n",
    "import random\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('/home/siddharth/MRM_SiddharthReddy/DL_Task/mnist_train.csv')\n",
    "data_test = pd.read_csv('/home/siddharth/MRM_SiddharthReddy/DL_Task/mnist_test.csv')\n",
    "data_test = np.array(data_test)\n",
    "data_train = np.array(data_train)\n",
    "np.random.shuffle(data_train)\n",
    "np.random.shuffle(data_test)\n",
    "m1,n1 = data_test.shape\n",
    "m2,n2 = data_train.shape\n",
    "data_test = data_test[0:m1].T\n",
    "Y_test = data_test[0]\n",
    "X_test = data_test[1:n1]\n",
    "X_test = X_test / 255.\n",
    "\n",
    "data_train = data_train[0:m2].T\n",
    "split_ratio = 0.8 \n",
    "\n",
    "split_index = int(m2 * split_ratio)\n",
    "\n",
    "X_train = data_train[1:n2, :split_index]\n",
    "Y_train = data_train[0, :split_index]\n",
    "\n",
    "X_val = data_train[1:n2, split_index:]\n",
    "Y_val = data_train[0, split_index:]\n",
    "\n",
    "X_train = X_train / 255.\n",
    "X_val = X_val / 255.\n",
    "\n",
    "_, m_train = X_train.shape\n",
    "_, m_val = X_val.shape\n",
    "\n",
    "# def apply_augmentations(images):\n",
    "#     seq = iaa.Sequential([\n",
    "#         iaa.GaussianBlur(sigma=(0, 1.0)),\n",
    "#         iaa.Affine(rotate=(-10, 10)),\n",
    "#         iaa.Fliplr(0.5),\n",
    "#     ])\n",
    "    \n",
    "#     augmented_images = seq.augment_images(images.reshape(-1, 28, 28, 1))\n",
    "#     return augmented_images.reshape(-1, images.shape[1])  \n",
    "\n",
    "\n",
    "# X_train = apply_augmentations(X_train)\n",
    "# X_test = apply_augmentations(X_test)\n",
    "# example_index = random.randint(0, X_train_augmented.shape[0] - 1)\n",
    "\n",
    "\n",
    "# current_image = (X_train[example_index] * 255)\n",
    "\n",
    "# plt.gray()\n",
    "# plt.imshow(current_image, interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    W1 = np.random.rand(20, 784) - 0.5  \n",
    "    b1 = np.random.rand(20, 1) - 0.5\n",
    "    W2 = np.random.rand(15, 20) - 0.5 \n",
    "    b2 = np.random.rand(15, 1) - 0.5\n",
    "    W3 = np.random.rand(10, 15) - 0.5  \n",
    "    b3 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "    \n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(W1, b1, W2, b2, W3, b3, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = ReLU(Z2)\n",
    "    Z3 = W3.dot(A2) + b3\n",
    "    A3 = softmax(Z3)\n",
    "    return Z1, A1, Z2, A2, Z3, A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_deriv(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, Y):\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ3 = A3 - one_hot_Y\n",
    "    dW3 = 1 / m1 * dZ3.dot(A2.T)\n",
    "    db3 = 1 / m1 * np.sum(dZ3, axis=1, keepdims=True)\n",
    "    dZ2 = W3.T.dot(dZ3) * ReLU_deriv(Z2)\n",
    "    dW2 = 1 / m1 * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m1 * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = 1 / m1 * dZ1.dot(X.T)\n",
    "    db1 = 1 / m1 * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    return dW1, db1, dW2, db2, dW3, db3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_params(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "    W3 = W3 - alpha * dW3\n",
    "    b3 = b3 - alpha * db3\n",
    "    return W1, b1, W2, b2, W3, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A3):\n",
    "    return np.argmax(A3, axis=0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    accuracy = accuracy_score(Y, predictions)\n",
    "    return accuracy\n",
    "\n",
    "def cost_fn(A3, Y):\n",
    "    m = Y.shape[0]  \n",
    "    epsilon = 1e-15  \n",
    "    cost = -1/m * np.sum(Y * np.log(A3 + epsilon))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 16987.670265293258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 8126.191562204309\n",
      "Cost: 6927.6631576632535\n",
      "Cost: 5469.506052057505\n",
      "Cost: 4792.497015316516\n",
      "Cost: 4444.498044200555\n",
      "Cost: 3447.12260374717\n",
      "Cost: 3196.8079512105564\n",
      "Cost: 3017.878694079264\n",
      "Cost: 2817.3285905178113\n",
      "Cost: 2604.7556969418606\n",
      "Cost: 2500.559021927913\n",
      "Cost: 2669.3556389710934\n",
      "Cost: 2195.2229775245223\n",
      "Cost: 2113.716783250102\n",
      "Cost: 2318.407680316063\n",
      "Cost: 1987.3441483563965\n",
      "Cost: 2030.7363806821368\n",
      "Cost: 1941.6779374903163\n",
      "Cost: 1845.8901144572392\n",
      "Cost: 1827.2268310056254\n",
      "Cost: 1869.9757824574217\n",
      "Cost: 1909.7600804376898\n",
      "Cost: 1684.3855066306999\n",
      "Cost: 1650.4866177038211\n",
      "Cost: 1668.123022703584\n",
      "Cost: 1818.3891352306591\n",
      "Cost: 1586.7153552635336\n",
      "Cost: 1547.9504783973757\n",
      "Cost: 1663.3889904375865\n",
      "Cost: 1551.6249601927186\n",
      "Cost: 1489.956470858993\n",
      "Cost: 1466.5984505259441\n",
      "Cost: 1447.033762909821\n",
      "Cost: 1429.6919570566452\n",
      "Cost: 1422.577190421152\n",
      "Cost: 1593.1188226831564\n",
      "Cost: 1432.3085294688624\n",
      "Cost: 1376.559953345178\n",
      "Cost: 1363.1747304583168\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2, W3, b3 = init_params()\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2, Z3, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)\n",
    "        cost = cost_fn(A3, one_hot(Y))\n",
    "        costs.append(cost)\n",
    "\n",
    "        dW1, db1, dW2, db2, dW3, db3 = backward_prop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, Y)\n",
    "        W1, b1, W2, b2, W3, b3 = update_params(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, alpha)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Cost:\", cost)\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3, costs\n",
    "W1, b1, W2, b2, W3, b3, costs = gradient_descent(X_train, Y_train, 0.10, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2, W3, b3):\n",
    "    _, _, _, _, _, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)\n",
    "    predictions = get_predictions(A3)\n",
    "    return predictions\n",
    "    \n",
    "def test_prediction(index, W1, b1, W2, b2,W3,b3):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2,W3,b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      4753\n",
      "           1       0.96      0.96      0.96      5362\n",
      "           2       0.93      0.88      0.90      4845\n",
      "           3       0.88      0.88      0.88      4830\n",
      "           4       0.92      0.91      0.91      4632\n",
      "           5       0.90      0.85      0.87      4379\n",
      "           6       0.94      0.96      0.95      4745\n",
      "           7       0.95      0.92      0.93      5038\n",
      "           8       0.85      0.91      0.88      4646\n",
      "           9       0.86      0.91      0.89      4770\n",
      "\n",
      "    accuracy                           0.91     48000\n",
      "   macro avg       0.91      0.91      0.91     48000\n",
      "weighted avg       0.91      0.91      0.91     48000\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       980\n",
      "           1       0.97      0.96      0.97      1135\n",
      "           2       0.92      0.88      0.90      1032\n",
      "           3       0.87      0.89      0.88      1010\n",
      "           4       0.92      0.90      0.91       982\n",
      "           5       0.90      0.86      0.88       892\n",
      "           6       0.93      0.94      0.93       958\n",
      "           7       0.95      0.90      0.93      1028\n",
      "           8       0.85      0.89      0.87       974\n",
      "           9       0.86      0.91      0.88      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "val Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1170\n",
      "           1       0.96      0.96      0.96      1380\n",
      "           2       0.93      0.87      0.90      1113\n",
      "           3       0.89      0.88      0.88      1301\n",
      "           4       0.92      0.90      0.91      1210\n",
      "           5       0.87      0.84      0.85      1042\n",
      "           6       0.92      0.94      0.93      1173\n",
      "           7       0.94      0.92      0.93      1227\n",
      "           8       0.85      0.90      0.87      1205\n",
      "           9       0.86      0.89      0.87      1179\n",
      "\n",
      "    accuracy                           0.91     12000\n",
      "   macro avg       0.91      0.91      0.91     12000\n",
      "weighted avg       0.91      0.91      0.91     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_predictions = make_predictions(X_train, W1, b1, W2, b2, W3, b3)\n",
    "train_report = classification_report(Y_train, train_predictions)\n",
    "print(\"train Set Classification Report:\")\n",
    "print(train_report)\n",
    "\n",
    "test_predictions = make_predictions(X_test, W1, b1, W2, b2, W3, b3)\n",
    "test_report = classification_report(Y_test, test_predictions)\n",
    "print(\"Test Set Classification Report:\")\n",
    "print(test_report)\n",
    "\n",
    "val_predictions = make_predictions(X_val, W1, b1, W2, b2, W3, b3)\n",
    "val_report = classification_report(Y_val, val_predictions)\n",
    "print(\"val Set Classification Report:\")\n",
    "print(val_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
